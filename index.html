<!DOCTYPE html>
<html lang="en">
<head>
  <title>Haocong Rao</title>
  <meta name="google-site-verification" content="7Kzam_Emj9XOvXlLCCTyPBQulC33nJn5Sa_hJdhUPQA" />
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,400;0,600;1,400;1,600&family=Ubuntu:ital,wght@0,400;0,500;1,400;1,500&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Ubuntu:ital,wght@0,400;0,500;1,400;1,500&display=swap" rel="stylesheet">
  <link href="./css/all.css" rel="stylesheet" type="text/css">
  <link href="./css/print.css" rel="stylesheet" type="text/css" media="print">
  <link rel="icon" href="images/logo.ico"  type="image/x-icon">
  <!-- Google tag (sorry for spying on you...) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-F9G053G7JN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-F9G053G7JN');
</script>


</head>

<body onload="setEmail()">
<div id="page">

<div id="navbar">
  <div class="container">
    <a href="https://haocongrao.github.io/" class="nav-head">Haocong Rao</a>
    <div class="nav-sep">&vert;</div>
    <a href="#publication" class="nav-item ">Publications</a>
      <div class="nav-sep">&vert;</div>
    <a href="https://github.com/Kali-Hac" class="nav-item ">Resources</a>
<!--        <div class="nav-sep">&vert;</div>-->
<!--       <a href="" class="nav-item ">CV</a>-->
   <a href="https://drive.google.com/file/d/1X8pWdSVKvIGvgSUi9CyWlAXJWUSCHSyF/view?usp=sharing" class="nav-item nav-right">CV</a>
  </div>
</div>

<div id="content">
  <div class="container">
<div class="intro-container">
<img class="intro-image no-print" src="./images/me.png" width="240" height="280" alt="Picture of me.">
<section id="wenjie-yin" class="intro-text">
<h1>Haocong Rao</h1>
    <p><strong>PhD Candidate, AISG PhD Fellow</strong></p>
    <p><strong>LILY Research Centre, Nanyang Technological University</strong></p>

<div class="intro-contact">
<table>
<tr class="contact-row">
<td class="contact-icon-cell">
<img class="contact-icon" alt="Email icon" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAYAAAA6/NlyAAAABmJLR0QA/wD/AP+gvaeTAAACqElEQVRoge2ZMWsUQRSAvySKUYygYCERRIlNUmhjFaNYqY1WdoqNWFkK/gBFBUFJYxFRkGBpZWeR2AliZREbQQWFFKJgEkyIOhY7J8vcm92Z2b27XXgfvGbnzdv5bm52Zu9AURRFURRFURQlgKGCtlFgDpjs01jqYgm4CqyndN4NvAZMS+ItsDdGcAfZzOYZAxYbIFMWi3aseUatk5dDwCtgl3N9G/C8AVK+eAFsd8a8E3hpnQqFfV+NEeBJA+TceAZsdcaaX4pBwgZ4D+x32oeA+w2Q7MRDYNgZ4z7gXS4nWNgAn4DDQt6NBsjeFcZ1EPjg5EUJG2AZOCrkXgP+DED0L3BdGM8U8EXIjxY2wA9gWsi/BGz2UfY3cEUYxzHgm6dPkrAB1oDTQp9zwK8+yG4AF4T7nwJ+FvRLFq5y06rh+7DPU/5hVxJO/VpViarLqbKwwf/gmER+cKTGMnBEuE/MA7MW4U6Ebg0pUdeWWKuwIWzzj40l5EPPg4RatQsbyo93MVH3sbYnwga4KNQbAxYiaizQ/caDrZ06rp4I3yuoGfqmJb3x5LnZFOHbQh33l5QtwHxBjXmbU1QDe6+BCkuyJ4A3wLhzfRiYFWrM0v3QG7c1ZmqQrk3YJ7tq2z8CE0LOWbIH0GPgjNA+YfsaYKUG6VqEpTV7nO7jpe/g4GMK+OrUWCM7urqErunKwr6ZXfHkf7ftZZy0uVKNKjNdSThWthObwC2yvdllD3CH8nNxqnSycKpsPtbJ9to54BHZL40bEf1TpJOEpTU7TW9fCX0Ru6ajhZskmyIdJdxE2VjpYOEmy8ZIBwm3QTZUulS4TbIh0oXCI8K1GeK2nkGFb8uSnLw0fWZDZ/o/RX+IHwCekv0L1yZWgcvA50EPRFEURVEURVGUFvMPaCH0Kag3FocAAAAASUVORK5CYII=">
</td>
<td class="contact-link-cell">
<strong><span class="my-email"></span></strong>
</td>
</tr>
<!--<tr>-->
<!--<td class="contact-icon-cell">-->
<!--<img class="contact-icon" alt="LinkedIn icon" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAABmJLR0QA/wD/AP+gvaeTAAABo0lEQVRoge2ZvUrEQBRGT1SwEdfCWiz0ESzFUsFd1lYUO0ufwUIWfBCfYTs1iqXvYCfq4iImlQhrEUUTZjIz+b24c+A24c7M+chO/hY8Hk9R+kAIxMCk5YqBa6DnGuJcgLyuBrYh+gJkTdW1CRIKEDXVVVY6UASJgAWbxC0SAYt/D6iCTJpxKU3KfaYti6qZ2iBPwD6w/F2HwKhqqarIu1psK/rbulyncN3sHeBdcewtZ0xdlNrsW4pjm8Vd6iXvdI6AI373yAHwbBgj8qclCX8fEY1rkEBTLj13JPeiFWCe5JlpAzgFXh19crHeYJoxOl6AHcPaS8DQ4GBaRylVZZA1m8WBOeDW4NFqEBdWgY+CLkqpuoLMWvRcuLg0fdU6AR6BT+ABOM7pHZZdrK4zsqeZU/f+vV7QpfYgN5o5Q01/R2qQsWbOsaY/cHFxfdZS9WfH2PQUmTd3zNQ+oojFB5GGDyINH0Qa/yaI/4oiDVWQuHELd7KfbZVB7hsQKYuVYw/zi3/btWubeCBAVldntiF+6JL8exoJkI+ASxzOhMfjSfMFRzMGRV1gLKEAAAAASUVORK5CYII=">-->
<!--</td>-->
<!--<td class="contact-link-cell">-->
<!--<a href="https://www.linkedin.com/in/yinw/">LinkedIn</a>-->
<!--</td>-->
<!--</tr>-->
<tr class="contact-row">
<td class="contact-icon-cell">
<img class="contact-icon" alt="Google Scholar icon" src="data:image/png;base64,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">
</td>
<td class="contact-link-cell">
    <a href="https://scholar.google.com.sg/citations?user=JkT65uQAAAAJ&hl=zh-CN&oi=ao"><strong>Google Scholar</strong></a>
</td>
</tr>
<tr class="contact-row">
<td class="contact-icon-cell">
<img class="contact-icon" alt="Github icon" src="data:image/png;base64,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">
</td>
<td class="contact-link-cell">
<a href="https://github.com/Kali-Hac"><strong>Github</strong></a>
</td>
</tr>
    <tr class="contact-row">
    <td class="contact-icon-cell">
    <img class="contact-icon" alt="ResearcgGate icon" src="data:image/png;base64,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">
    </td>
    <td class="contact-link-cell">
    <a href="https://www.researchgate.net/profile/Haocong_Rao2"><strong>ResearchGate</strong></a>
    </td>
    </tr>
</table>
</div>
</section>
</div>
<strong>
<h2 id="about-me">About me</h2>
<p>
 I am Haocong Rao (饶浩聪), a final-year PhD candidate supported by
   <a href="https://aisingapore.org/research/phd-fellowship-programme/">AI Singapore (AISG) PhD Fellowship</a> and supervised by <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Prof. Chunyan</a> (<em>FIEEE, Fellow of the Academy of Engineering Singapore</em>) and <a href="https://ece.ubc.ca/cyril-leung/">Prof. Cyril Leung</a> (<em>Fellow of the Engineering Institute of Canada</em>),
    at the <a href="https://www.ntu.edu.sg/lily">LILY Research Centre</a> and College of Computing and Data Science (CCDS), Nanyang Technological University (NTU), Singapore.
    My broad research interests include Skeleton-Based Person Re-Identification (SRID), 3D Signal Processing, Self-Supervised/Unsupervised learning, Interdisciplinary AI (<em>e.g.</em>, LLMs Application, AI for Healthcare).
</p>

<p>
      Prior to joining NTU, I was a research assistant at the Shenzhen Institutes of Advanced Technology (SIAT), Chinese Academy of Science,
      where my supervisors and academic mentors were <a href="https://smt.bit.edu.cn/szdw/jsml/bssds/a28d1679c3ba43ae931471d721f28e31.htm">Prof. Xiping Hu</a>, <a href="https://www.suat-sz.edu.cn/info/1150/1933.htm">Prof. Jun Cheng</a>, <a href="https://scholar.google.com/citations?user=5kcgY8MAAAAJ&hl=zh-CN">Prof. Bin Hu</a>, and <a href="https://ece.ubc.ca/victor-leung/">Prof. Victor C.M. Leung</a> (<em>FIEEE, FRSC, FEIC, FCAE</em>).
      I obtained my B.Eng. degree with Outstanding Thesis Award from South China University of Technology (SCUT).
</p>
<!--      <em><stronghuge><font color="#a82e2e">I am on the 2024-2025 academic job market. </font></stronghuge></em> <br>-->
</strong>
<tbody><tr>
        <td width="100%" valign="middle">
        <h2>News</h2>
        <p>
         <li> <strongsmall>[2024/05]</strongsmall> &nbsp;&nbsp;<smalll>One survey paper
            "A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis" is released!</smalll><br></li>
          <li> <strongsmall>[2024/03]</strongsmall> &nbsp;&nbsp;<smalll>We are organizing the
              <EM><a href="https://ijcai-aiaa-2024.org/">The 4th AI for Ageless Aging Workshop (AIAA) workshop</a></EM>,
           conjunction with
              <EM><a href="https://ijcai24.org/">IJCAI 2024</a></EM>, now calling for papers!
         </smalll><br></li>
            <li> <strongsmall>[2024/01]</strongsmall> &nbsp;&nbsp;<smalll>One survey paper "A Survey on 3D Skeleton Based Person Re-Identification: Approaches, Designs,
                Challenges, and Future Directions" is released!</smalll><br></li>
            <li> <strongsmall>[2023/10]</strongsmall> &nbsp;&nbsp;<smalll>One paper (LLMs for Psychology) is accepted by <em>Findings of EMNLP 2023</em>!</smalll><br></li>
            <li> <strongsmall>[2023/10]</strongsmall> &nbsp;&nbsp;<smalll>Awarded <strong>Outstanding Contribution Award</strong> of <em>European Alliance for Innovation
(EAI), International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness</em>.</smalll><br></li>
            <li> <strongsmall>[2023/07]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>International Journal of Computer Vision (IJCV) [IF: 19.5]</em>!</smalll><br></li>
            <li> <strongsmall>[2023/03]</strongsmall> &nbsp;&nbsp;<smalll>Our <em>TPAMI [IF: 24.3]</em> article "A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D Skeleton Based Person Re-Identification" is recognized as <em><strong style="color: red;">ESI Highly Cited Paper</strong></em>!</smalll><br></li>
            <li> <strongsmall>[2023/02]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>CVPR 2023</em>!</smalll><br></li>
<!--            <li> <strongsmall>[2022/12]</strongsmall> &nbsp;&nbsp;<smalll>Invited to serve as a Program Committee member of <em>IJCAI 2023</em>!</smalll><br></li>-->
            <li> <strongsmall>[2022/10]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IEEE Signal Processing Letters [IF: 3.9]</em>!</smalll><br></li>
          <li> <strongsmall>[2022/09]</strongsmall> &nbsp;&nbsp;<smalll>Our <em>TPAMI </em> article "A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D Skeleton Based Person Re-Identification" is selected as <em><strong style="color: red;">Featured Article (2022 October Issue) of TPAMI</strong></em>!</smalll><br></li>
            <li> <strongsmall>[2022/09]</strongsmall> &nbsp;&nbsp;<smalll>Recognized as <strong>Top Reviewer (3%)</strong> and <strong>Distinguished Program Committee (PC) Member</strong> of <em>IJCAI! </em> </smalll><br></li>
          <li> <strongsmall>[2022/04]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IJCAI 2022 (Oral)</em>!</smalll><br></li>
            <li> <strongsmall>[2021/11]</strongsmall> &nbsp;&nbsp;<smalll>Awarded <em><strong style="color: red;">AI Singapore (AISG) PhD Fellowship</strong> (Top PhD Scholarship in Singapore)</em>!</smalll><br></li>
            <li> <strongsmall>[2021/11]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IEEE Transactions on Multimedia (TMM) [IF: 8.2]</em>!</smalll><br></li>
          <li> <strongsmall>[2021/07]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>ACMMM 2021</em>!</smalll><br></li>
            <li> <strongsmall>[2021/06]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) [IF: 24.3]</em>!</smalll><br></li>
          <li> <strongsmall>[2021/04]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IJCAI 2021 (Oral)</em>!</smalll><br></li>
                        <li> <strongsmall>[2021/03]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IEEE Internet of Things Journal (IoTJ) [IF: 10.2]</em>!</smalll><br></li>
            <li> <strongsmall>[2021/03]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>Information Sciences [IF: 8.5]</em>!</smalll><br></li>
            <li> <strongsmall>[2020/12]</strongsmall> &nbsp;&nbsp;<smalll>Our paper "Multi-level Co-Occurrence Graph Convolutional LSTM for Skeleton-Based Action Recognition" received <strong>2020 IEEE Healthcom Best Paper Award</strong> at <em>IEEE International Conference on E-health Networking, Application & Service</em>!</smalll><br></li>
            <li> <strongsmall>[2020/12]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IEEE Internet of Things Journal (IoTJ) [IF: 9.5]</em>!</smalll><br></li>
            <li> <strongsmall>[2020/10]</strongsmall> &nbsp;&nbsp;<smalll>Awarded <strong>Dean's Research Excellence Scholarship (Special Award)</strong> at Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences (SIAT)!</smalll><br></li>
            <li> <strongsmall>[2020/04]</strongsmall> &nbsp;&nbsp;<smalll>One paper is accepted by <em>IJCAI 2020 (Oral)</em>!</smalll><br></li>
          <p></p>
        </li></td>
      </tr>
</tbody>

<tbody><tr>
    <div id="publication">
        <td width="100%" valign="middle">
         <h2>Selective Articles <a href="https://scholar.google.com.sg/citations?user=JkT65uQAAAAJ&hl=zh-CN&oi=ao" style="font-size:22px;">[Google Scholar]</a>
              <a href="https://www.researchgate.net/profile/Haocong_Rao2" style="font-size:22px;">[ResearchGate]</a></h2>
        </td>
    </div>
      </tr>
</tbody>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td align="center" width="25%">
        <img src="./images/AI4NDD_overview.png" width="190" height="130">
      </td>
      <td valign="top" width="75%">
      <strong>A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis</strong><br>
       By <strong><u>Haocong Rao</a></u></strong>,
       <a href="">Minlin Zeng</a>,
          <a href="https://scholar.google.com/citations?user=gcXa1o8AAAAJ&hl=en">Xuejiao Zhao</a>,
       <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>

	 <em>Arxiv Preprint</em><br>
     <a href="https://arxiv.org/abs/2405.13082">[Link]</a>
          <a href="https://arxiv.org/pdf/2405.13082">[PDF]</a>
     <a href="https://github.com/Kali-Hac/AI4NDD-Survey">[Resources]</a>
<!--      <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:pyQiJYbu3PgJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGam3o:AFWwaeYAAAAAZmGcg3p1n0naJ3OA-ZyEzQ3rhZc&scisig=AFWwaeYAAAAAZmGcgwd3gxarwEQ8c5xugpkq5jY&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
        <p></p>
      </td>
    </tr>
   </tbody></table>

 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td align="center" width="25%">
        <img src="./images/SRID_overview.jpeg" width="190" height="150">
      </td>
      <td valign="top" width="75%">
      <strong>A Survey on 3D Skeleton Based Person Re-Identification: Approaches, Designs, Challenges, and Future Directions</strong><br>
       By <strong><u>Haocong Rao</a></u></strong>,
       <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>

          <em>Arxiv Preprint</em><font color="#6495ed"> [First SRID Survey]</font><br>
     <a href="https://arxiv.org/abs/2401.15296">[Link]</a>
           <a href="https://arxiv.org/pdf/2401.15296">[PDF]</a>
     <a href="https://github.com/Kali-Hac/3D-skeleton-based-person-re-ID-survey">[Resources]</a>
<!--      <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:B-L8WFJb_b8J:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGaquw:AFWwaeYAAAAAZmGcsuztIpWW1VDG8RiO_e3jOmE&scisig=AFWwaeYAAAAAZmGcsmOdDqGpNho4lBC1twerYq0&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
        <p></p>
      </td>
    </tr>
   </tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td align="center" width="25%">
        <img src="./images/Hi-MPC_overview.jpeg" width="190" height="100">
      </td>
      <td valign="top" width="75%">
      <strong>Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification</strong><br>
       By <strong><u>Haocong Rao</u></strong>,
           <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Cyril Leung</a>,
        <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>
          <em>International Journal of Computer Vision (<strong>IJCV</strong>) 2023 [IF: 19.5]</em> <font color="#6495ed">[First SRID Article in IJCV]</font><br>
     <a href="https://arxiv.org/pdf/2307.12917">[Link]</a>
          <a href="https://drive.google.com/file/d/1Z6LBFjyPlbUtFoQ1xsuGerpfwuZo8D7m/view?usp=drive_link">[PDF]</a>
     <a href="https://github.com/Kali-Hac/Hi-MPC">[Code]</a>
     <a href="https://github.com/Kali-Hac/Hi-MPC">[Data]</a>
<!--     <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:VpPgrO5jm88J:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGbLOM:AFWwaeYAAAAAZmGdNOP5g9qEkspEuUxxemVLblc&scisig=AFWwaeYAAAAAZmGdNCqTybI_Ue-7bRdZZGFhiE8&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
        <p></p>
      </td>
    </tr>
   </tbody></table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td align="center" width="25%">
        <img src="./images/ChatGPT-MBTI_overview.png" width="190" height="150">
      </td>
      <td valign="top" width="75%">
      <strong>Can ChatGPT Assess Human Personalities? A General Evaluation Framework</strong><br>
      By <strong><u>Haocong Rao</u></strong>,
           <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Cyril Leung</a>,
        <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>
     <em>2023 Conference on Empirical Methods in Natural Language Processing,<strong> EMNLP 2023</strong> (Findings)</em><br>
     <a href="https://arxiv.org/abs/2303.01248">[Link]</a>
          <a href="https://drive.google.com/file/d/1h9h-buTrJu62L83LXdJF1hmKZPihpOKp/view?usp=drive_link">[PDF]</a>
     <a href="https://github.com/Kali-Hac/ChatGPT-MBTI">[Code]</a>
<!--     <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:IG7yxaVDZHEJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGbfVM:AFWwaeYAAAAAZmGdZVPdpjPibYvchnMoHVAslh0&scisig=AFWwaeYAAAAAZmGdZRAOMjDcYOtqgtrfkez4D10&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <p></p>
      </td>
    </tr>
   </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/TranSG_overview.png" width="190" height="140">
      </td>
      <td valign="top" width="75%">
	 <strong>TranSG: Transformer-Based Skeleton Graph Prototype Contrastive Learning with Structure-Trajectory Prompted Reconstruction for Person Re-Identification</strong><br>
	 By <strong><u>Haocong Rao</u></strong>,
        <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>
     <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2023</strong></em> <font color="#6495ed">[First SRID Paper in CVPR]</font><br>
		<a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Rao_TranSG_Transformer-Based_Skeleton_Graph_Prototype_Contrastive_Learning_With_Structure-Trajectory_Prompted_CVPR_2023_paper.pdf">[Link]</a>
        <a href="https://drive.google.com/file/d/16BlucHoTZAcV-ayHgweaqW_jQyaH3q2G/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/TranSG">[Code]</a>
         <a href="https://github.com/Kali-Hac/TranSG">[Data]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:eAZuvWdZxCUJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGaML0:AFWwaeYAAAAAZmGcKL1lVaz0kzqVHOMov2pahdo&scisig=AFWwaeYAAAAAZmGcKHNaXcsdfKLcnuk8ZOTUVjA&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/SPL_overview.png" width="190" height="100">
      </td>
      <td valign="top" width="75%">
          <strong>Revisiting <em>k</em>-Reciprocal Distance Re-ranking for Skeleton-Based Person Re-Identification</strong><br>
	 By <strong><u>Haocong Rao</u></strong>,
          Yuan Li,
        <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>
     <em>IEEE Signal Processing Letters 2022 [IF: 3.9]</em><br>
		<a href="https://ieeexplore.ieee.org/abstract/document/9913633">[Link]</a>
          <a href="https://drive.google.com/file/d/1RrvF1paavKHFOSImji0ALk8vMrqrJ9Fw/view?usp=drive_link">[PDF]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:i5ogNWi3beIJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGbhs0:AFWwaeYAAAAAZmGdns18Ej7434bRkbMW_u7yHcQ&scisig=AFWwaeYAAAAAZmGdnir1gmBgmCfV1Zftwk1FauM&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/SimMC_overview.png" width="190" height="160">
      </td>
      <td valign="top" width="75%">
	 <strong>SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification</strong><br>
	By <strong><u>Haocong Rao</u></strong>,
        <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>
          <em>31st International Joint Conference on Artificial Intelligence, <strong>IJCAI 2022 <font color="red">(Oral, Acceptance Rate: 14.9%)</font></strong></em><br>
		<a href="https://www.ijcai.org/proceedings/2022/0180.pdf">[Link]</a>
           <a href="https://drive.google.com/file/d/1r3HKC2B_Mbt-ofiOQsQ26uK9s3nc1LGv/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/SimMC">[Code]</a>
         <a href="https://github.com/Kali-Hac/SimMC">[Data]</a>
<!--         <a href="https://www.ijcai.org/proceedings/2022/bibtex/0180">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/SPC-MGR_overview.png" width="190" height="120">
      </td>
      <td valign="top" width="75%">
	 <strong>Skeleton Prototype Contrastive Learning with Multi-Level Graph Relation Modeling for Unsupervised Person Re-Identification</strong><br>
	By <strong><u>Haocong Rao</u></strong>,
        <a href="https://dr.ntu.edu.sg/cris/rp/rp00084">Chunyan Miao</a><br>
     <em><strong>Arxiv Preprint (Extension of IJCAI 2021 Paper)</strong></em><br>
		<a href="https://arxiv.org/pdf/2208.11814">[Link]</a>
          <a href="https://drive.google.com/file/d/1R0i5nVOYrMhPqmtieuIrNHma0TP9XiZL/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/SPC-MGR">[Code]</a>
         <a href="https://github.com/Kali-Hac/SPC-MGR">[Data]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:so6Zk3uGItAJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGZ0Z4:AFWwaeYAAAAAZmGfyZ7YmpQwfXuz3I-fHW24zdU&scisig=AFWwaeYAAAAAZmGfyUYY0bDksUsHA7hRViDC9xQ&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/SM-SGE_overview.png" width="190" height="120">
      </td>
      <td valign="top" width="75%">
	 <strong>SM-SGE: A Self-Supervised Multi-Scale Skeleton Graph Encoding Framework for Person Re-Identification</strong><br>
	 By <strong><u>Haocong Rao</u></strong>, Xiping Hu, Jun Cheng, Bin Hu <br>
     <em>29th ACM International Conference on Multimedia, <strong>ACMMM 2021</strong></em> <font color="#6495ed">[First SRID Paper in ACMMM]</font><br>
		<a href="https://arxiv.org/abs/2107.01903">[Link]</a>
          <a href="https://drive.google.com/file/d/1Tk4Ww3I3F7Zn0SVIemVE_0z4BjdyqcCl/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/SM-SGE">[Code]</a>
         <a href="https://github.com/Kali-Hac/SM-SGE">[Data]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:qN64Q6R5ja4J:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGbzCY:AFWwaeYAAAAAZmGd1CZvM8Xa4vXvt-VQ4P8-fRw&scisig=AFWwaeYAAAAAZmGd1OYqax0LhxsFItU5os2Wn1U&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/Locality_Awareness_overview.png" width="190" height="110">
      </td>
      <td valign="top" width="75%">
	 <strong>A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D Skeleton Based Person Re-Identification</strong><br>
	 By <strong><u>Haocong Rao</u>*</strong>, Siqi Wang*, Xiping Hu, Mingkui Tan, Yi Guo, Jun Cheng, Xinwang Liu, Bin Hu (* Co-First Author)<br>
     <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>) 2021 [IF: 24.3] (Extension of IJCAI 2020 Paper)
     </em> <font color="#6495ed">[First SRID Article in TPAMI]</font> <EM><strong><font color="red">(TPAMI Featured Article, ESI Highly Cited Paper)</font></strong></EM><br>
		<a href="https://ieeexplore.ieee.org/document/9466418">[Link]</a>
          <a href="https://drive.google.com/file/d/1uIu2QmKYt68YSenPmuBAFBULpH2mekpC/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/Locality-Awareness-SGE">[Code]</a>
         <a href="https://github.com/Kali-Hac/Locality-Awareness-SGE">[Data]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Zf_RPTCA-UkJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGb7_I:AFWwaeYAAAAAZmGd9_K5yy7DCUVHzLBBucNgIWo&scisig=AFWwaeYAAAAAZmGd94QF2WKAWRr4n7mOyQsb_PQ&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/MG-SCR_overview.png" width="190" height="120">
      </td>
      <td valign="top" width="75%">
	 <strong>Multi-level Graph Encoding with Structural-Collaborative Relation Learning for Skeleton-Based Person Re-Identification</strong><br>
	 By <strong><u>Haocong Rao</u></strong>, Shihao Xu, Xiping Hu, Jun Cheng, Bin Hu <br>
     <em>30th International Joint Conference on Artificial Intelligence, <strong>IJCAI 2021 <font color="red">(Oral, Acceptance Rate: 13.9%)</font></strong></em><br>
		<a href="https://www.ijcai.org/proceedings/2021/0135.pdf">[Link]</a>
          <a href="https://drive.google.com/file/d/1G99sJ2Ykua-DyG1liMzeZ6M7_juPhAM_/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/MG-SCR">[Code]</a>
         <a href="https://github.com/Kali-Hac/MG-SCR">[Data]</a>
<!--         <a href="https://www.ijcai.org/proceedings/2021/bibtex/0135">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/AS-CAL_overview.png" width="190" height="120">
      </td>
      <td valign="top" width="75%">
	 <strong>Augmented Skeleton Based Contrastive Action Learning with Momentum LSTM for Unsupervised Action Recognition</strong><br>
	 By <strong><u>Haocong Rao</u>*</strong>, Shihao Xu*, Xiping Hu, Jun Cheng, Bin Hu (* Co-First Author)<br>
     <em>Information Sciences 2021 [IF: 8.5]</em><br>
		<a href="https://www.sciencedirect.com/science/article/pii/S0020025521003443">[Link]</a>
          <a href="https://drive.google.com/file/d/1qsfh3YZfZM7D7r8oyOObP4P54T4EAYFw/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Kali-Hac/AS-CAL">[Code]</a>
         <a href="https://github.com/Kali-Hac/AS-CAL">[Data]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Jl-F5er8t8cJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGYMd0:AFWwaeYAAAAAZmGeKd0N_evvyeshZYJBd8aEOsE&scisig=AFWwaeYAAAAAZmGeKUg_G1pArSptfBGJAPzn1AA&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/IoT_overview.jpg" width="140" height="120">
      </td>
      <td valign="top" width="75%">
	 <strong>Internet of Things Enabled Data Fusion Method for Sleep Healthcare Applications</strong><br>
	 By Fan Yang, Qilu Wu, Xiping Hu, Jiancong Ye, Yuting Yang, <strong><u>Haocong Rao</u></strong>, Rong Ma, Bin Hu<br>
     <em>IEEE Internet of Things Journal (<strong>IoTJ</strong>) 2021 [IF: 10.2]</em><br>
		<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9383097">[Link]</a>
          <a href="https://drive.google.com/file/d/12QnHN_MjsBUZL7vjleEp7VGZT7fer4T8/view?usp=drive_link">[PDF]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:Jl-F5er8t8cJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGYMd0:AFWwaeYAAAAAZmGeKd0N_evvyeshZYJBd8aEOsE&scisig=AFWwaeYAAAAAZmGeKUg_G1pArSptfBGJAPzn1AA&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>

       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()"></tr>
      <tr><td align="center" width="25%">
        <img src="./images/PCRP_overview.png" width="190" height="120">
      </td>
      <td valign="top" width="75%">
	 <strong>Prototypical Contrast and Reverse Prediction: Unsupervised Skeleton Based Action Recognition</strong><br>
	 By Shihao Xu, <strong><u>Haocong Rao</u></strong>, Xiping Hu, Jun Cheng, Bin Hu<br>
     <em>IEEE Transactions on Multimedia (<strong>TMM</strong>) 2021 [IF: 8.2]</em><br>
		<a href="https://ieeexplore.ieee.org/abstract/document/9623511">[Link]</a>
           <a href="https://drive.google.com/file/d/1TFzmIZUdEAhbe3n2bJImqevpNtr4oCJr/view?usp=drive_link">[PDF]</a>
         <a href="https://github.com/Mikexu007/PCRP">[Code]</a>
         <a href="https://github.com/Mikexu007/PCRP">[Data]</a>
<!--         <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:_kGdRKnLaPgJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGYVjU:AFWwaeYAAAAAZmGeTjVYz-uL7YPnb0fQR7bJN7k&scisig=AFWwaeYAAAAAZmGeTrgT1lA7W7T_EBN-GSmoudo&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
          <br>
        <p></p>
      </td>
    </tr>
   </tbody></table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td align="center" width="25%">
        <img src="./images/MCGC-LSTM_overview.png" width="190" height="120">
      </td>
      <td valign="top" width="75%">
      <strong>Attention based Multi-level Co-occurrence Graph Convolutional LSTM for 3D Action Recognition</strong><br>
         By Shihao Xu*, <strong><u>Haocong Rao</u>*</strong>, Xiping Hu, Jun Cheng, Bin Hu (* Co-First Author)<br>
     <em>IEEE Internet of Things Journal (<strong>IoTJ</strong>) 2020 [IF: 9.5]</em><br>
     <a href="https://ieeexplore.ieee.org/document/9286840">[Link]</a>
           <a href="https://drive.google.com/file/d/1vXN97PlH9EdcDh011wKSDyqdm2dndfur/view?usp=drive_link">[PDF]</a>
     <a href="https://github.com/Mikexu007/AMCGC-LSTM">[Code]</a>
<!--     <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:gLVTmfTtiP0J:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGYd6M:AFWwaeYAAAAAZmGeb6NvtvtFSp_poN7dA3RMnGk&scisig=AFWwaeYAAAAAZmGebwIbp0yvit_AhZNwjhg_qPo&scisf=4&ct=citation&cd=-1&hl=zh-CN">[Bibtex]</a>-->
     <p></p>
      </td>
    </tr>
   </tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td align="center" width="25%">
        <img src="./images/SGE-LA_overview.png" width="190" height="100">
      </td>
      <td valign="top" width="75%">
      <strong>Self-Supervised Gait Encoding with Locality-Aware Attention for Person Re-Identification</strong><br>
          By <strong><u>Haocong Rao</u>*</strong>, Siqi Wang*, Xiping Hu, Mingkui Tan, Huang Da, Jun Cheng, Bin Hu. (* Co-First Author)<br>
     <em>29th International Joint Conference on Artificial Intelligence, <strong>IJCAI 2020 <font color="red">(Oral, Acceptance Rate: 12.6%)</font></strong></em> <font color="#6495ed">[First SRID Paper in IJCAI]</font><br>
     <a href="https://www.ijcai.org/proceedings/2020/0125.pdf">[Link]</a>
          <a href="https://drive.google.com/file/d/1UIrGrGgiXYv_cGesqwijzydUI-iJBTcG/view?usp=drive_link">[PDF]</a>
     <a href="https://github.com/Kali-Hac/SGE-LA">[Code]</a>
     <a href="https://github.com/Kali-Hac/SGE-LA">[Data]</a>
<!--     <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:lpWaw3IqRLYJ:scholar.google.com/&output=citation&scisdr=ClErLFgYENjS5dGYs44:AFWwaeYAAAAAZmGeq44MTMwRDMT3w-x0zpoJoLE&scisig=AFWwaeYAAAAAZmGeq2lCAd7m8RGhDo2TfT5dN6M&scisf=4&ct=citation&cd=-1&hl=zh-CN&scfhb=1">[Bibtex]</a>-->
     <p></p>
      </td>
    </tr>
   </tbody></table>

<tbody><tr>
    <td width="100%" valign="middle">
      <h2>Professional Services & Teaching</h2>
      <div style="line-height:25px">
      <p>
      </p>
      <li> Editorial Board Member of Frontiers in Computational Neurosciencer</li>
      <li> Program Committee (PC) Member of <EM>IJCAI</EM> 2022, 2023, 2024 <br></li>
      <li> Co-Organizer and PC Member of
          <a href="https://ijcai-aiaa-2024.org/">the 4th AI for Ageless Aging Workshop</a> @<EM>IJCAI 2024</EM><br></li>
      <li> Co-Organizer and PC Member of
          <a href="https://zxjwudi.github.io/aiaa2023.github.io/">the 3rd AI for Ageless Aging Workshop</a> @<EM>IJCAI 2023</EM><br></li>
      <li> Organizing Team Member of
          <a href="http://iccse2023.crowdscience.org/">the 6th International Conference on Crowd Science and Engineering</a> @<EM>ICCSE 2023</EM><br></li>
      <li> Co-Host, Co-Organizer, and PC Member of
          <a href="https://zxjwudi.github.io/aif2022.github.io/">the 2nd AI for Cognitive and Physical Frailty Seminar</a> @<EM>IJCAI 2022</EM><br></li>
          <br>
           <li> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Reviewer </li>
           <li> International Journal of Computer Vision (IJCV), Reviewer </li>
           <li> IEEE Transactions on Image Processing (TIP), Reviewer</li>
          <li> IEEE Transactions on Industrial Informatics (TII), Reviewer </li>
           <li> IEEE Transactions on Affective Computing (TAC), Reviewer </li>
          <li> IEEE Journal of Biomedical and Health Informatics (JBHI), Reviewer </li>
           <li> IEEE Transactions on Multimedia (TMM), Reviewer </li>
           <li> Artificial Intelligence Review, Reviewer </li>
           <li> Expert Systems with Applications, Reviewer </li>
<!--          <li> "xxx", AI Time, 2021.10 &nbsp;<a href="https://www.bilibili.com/video/BV1qP4y1b7us?spm_id_from=333.999.0.0">[Video]</a><br></li>-->
          <br>
          <li> CZ3004 Multi-disciplinary Design Project, Teaching Assistant, NTU, 2022 Fall </li>
           <li> SC1003 Introduction to Computational Thinking and Programming, Teaching Assistant, NTU, 2023 Fall </li>
      <p></p>
      </li></div>
    </td>
  </tr>
</tbody>


<tbody><tr>
        <td width="100%" valign="middle">
          <h2>Selective Projects &amp; Awards &amp; Honors </h2>
          <div style="line-height:25px">
          <p></p>
          <li> <stronghuge><STRONG><u>Project Lead</u></STRONG> of AI Singapore PhD Research Project (of National Research Foundation, Singapore) (2022 to 2025): <EM>“Research and Application of AI for Skeleton-Based Person Re-Identification”</EM></li>
            <li> <stronghuge><STRONG><u>Participator</u></STRONG> of the National Science and Technology Innovation Project (2018 to 2020): <EM>“Research and Development of Non-Invasive Gait * System”.</EM></li>
              <li> <stronghuge><STRONG><u>Participator</u></STRONG> of Shenzhen Sustainable Development of Science and Technology Project (2021 to 2023): <EM>“Clinical Application and Research on Gait and Multi-Modal Analysis Based Elderly Fall and Protection System”.</EM></li>
                <li> <stronghuge><STRONG><u>Participator</u></STRONG> of Alibaba-NTU Joint Research Institute Project (2022 to 2025)</li>
              <br>
              The developed 4D Depth Video Based Gait Recognition & Emotion Prediction System and the Swarm Intelligence Computing and Multi-Sensor Based Sleep Monitoring System 
              have been applied to various universities and
              hospitals with more than 10,000 clinical experiments, including: 
              State Key Laboratory of Cognitive Neuroscience and Learning of Beijing Normal University, Peking University Sixth Hospital, 
              the Second Xiangya Hospital, Shenzhen People’s Hospital, etc.
              <br>
              <br>
              <li> <stronghuge><STRONG>Outstanding Contribution Award</STRONG>, European Alliance for Innovation (EAI), International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness, 2023 </stronghuge><br></li>
              <li> <STRONG>Outstanding Reviewer</STRONG> of IJCAI (Top 3% Reviewer), 2022<br></li>
              <li> <stronghuge><STRONG>Distinguished PC Member</STRONG> of IJCAI, 2022</stronghuge><br></li>
              <li> <stronghuge> <STRONG>One ESI Highly Cited Paper & TPAMI Featured Article</STRONG> (2022 October Issue)</stronghuge><br></li>
              <li> <stronghuge><STRONG>AI Singapore (AISG) PhD Fellowship</STRONG> (Top PhD Scholarship in SG), 2022-2025</stronghuge><br></li>
              <li> <stronghuge><STRONG>Dean's Research Excellence Scholarship (Special Award)</STRONG> of SIAT, 2020</stronghuge><br></li>
              <li> <stronghuge><STRONG>IEEE Healthcom Best Paper Award</STRONG>, 2020</stronghuge><br></li>
              <li> <stronghuge><STRONG>Outstanding Undergraduate Thesis Award</STRONG> of SCUT, 2019</stronghuge> <br></li>
              <li> <stronghuge><STRONG>National Scholarship</STRONG>, Ministry of Education of China, 2018 </stronghuge><br></li>
              <li> <stronghuge><STRONG>2nd Place (Leader)</STRONG> in South China Hackathon of Microsoft, 2018 </stronghuge><br></li>
              <li> <stronghuge><STRONG>1st Place (Leader)</STRONG> in Wenshi Software Design Contest of SCUT, 2018</stronghuge><br></li>
              <li> <stronghuge><STRONG>Outstanding Student Association</STRONG> (Leader) of SCUT SSE, 2017</stronghuge><br></li>
              <li> <stronghuge><STRONG>1st Prize (Leader)</STRONG> in Creative Programming Design Contest of SCUT SSE, 2016</stronghuge><br></li>
              <p></p>
          </li></div>
        </td>
      </tr>
</tbody>


<tbody><tr>
        <td width="100%" valign="middle">
          <h2>Invited Talks</h2>
          <div style="line-height:25px">
          <p></p>
          <li> <stronghuge><STRONG>"Pioneering AI Innovations in Skeleton-Based Person Re-Identification"</STRONG>, Invited by <EM>Institute of Artificial Intelligence, Xiamen University</EM>, China, 2024 <br></li>
            <li> <stronghuge><STRONG>"Discussion and Advice on  <a href="https://www.smartnation.gov.sg/nais/">the National AI Stragtegy 2.0</a>"</STRONG>, Invited by <EM>AI Singapore Committee (of Singapore National Research Foundation)</EM>, NUS, Singapore, 2024 <br></li>
              <li> <stronghuge><STRONG>"Skeleton Prototype Contrastive Learning with Multi-Level Graph Relation Modeling for Unsupervised Person Re-Identification"</STRONG>, 
                              Invited by <EM>International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness</EM>, 2023</stronghuge><br></li>
              <li> <stronghuge><STRONG>"Insights from Top-Conference Research"</STRONG>, Invited by <EM>the Department of Computer Science and Engineering, Southern University of Science and Technology</EM>, China, 2021</stronghuge><br></li>
              <p></p>
          </li></div>
        </td>
      </tr>
</tbody>



<div id="leadership">
<tbody><tr>
<td width="100%" valign="middle">
  <h2>Leadership Experiences</h2>
</td>
</tr>
</tbody>
</div>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td width="15%">
        <img src="./images/SCSE_GSC_LOGO.png" width="200" height="200">
      </td>
      <td valign="top" width="75%">
          <stronghuge><STRONG>NTU CCDS (SCSE) Graduate Student Club (2021 - 2024)</STRONG></stronghuge> <br>
        <huge><em>Director of Publicity Committee & Member of Academic Committee</em></huge><br>
        <p></p>
        <p></p>
          <li> Organize talks, seminars, and gatherings more than 10 times (<EM>e.g.</EM>,
              <a href="https://www.youtube.com/@scse-gscnanyangtechnologic8474/videos">PhD Student Lecture Series</a>),
              which have gained over 6,300 video views on <a href="https://www.youtube.com/@scse-gscnanyangtechnologic8474/videos">Youtube</a>.<br></li>
<!--          <br>-->
          <li> Connect and invite various scholars for academic talks:
<!--          <ul>--><br>
               &nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://www.youtube.com/@scse-gscnanyangtechnologic8474/videos">PhD Student Lecture Series (SLS)</a>: CCDS (SCSE) PhD Students, AI Singapore (AISG) PhD Fellows<br>
              &nbsp&nbsp&nbsp&nbsp&nbsp<a href="https://www.youtube.com/@scse-gscnanyangtechnologic8474/videos">Graduate Chat Series</a>: NTU CCDS (SCSE) Outstanding PhD Thesis Awardees<br>
              &nbsp&nbsp&nbsp&nbsp&nbsp Invited Talk Series: NTU Predidential Postdoctoral Fellows, NTU Nanyang Assistant Professors, <EM>etc</EM>.
<!--          </ul>-->
           <li> Manage and promote CCDS (SCSE) social media publicity (<a href="https://www.youtube.com/@scse-gscnanyangtechnologic8474/videos/">Youtube (@SCSE-GSC)</a>,
          <a href="https://www.instagram.com/ntu.scse.gsc/">Instagram (@ntu.scse.gsc)</a>, <a href="https://x.com/SCSE_GSC">Twitter (@SCSE_GSC)</a>, Wechat (@NTU SCSE PhD), <EM>etc</EM>.),
          which has linked and served more than 320 NTU CCDS (SCSE) PhDs. <br></li>
        <p></p>
      </li></td>
    </tr>
   </tbody>
</table>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr onmouseout="aperture_stop()" onmouseover="aperture_start()">
      <td width="15%">
        <img src="./images/SCUT_SSE.jpg" width="200" height="140">
      </td>
      <td valign="top" width="75%">
          <stronghuge><STRONG>SCUT SSE Student Union (2015 - 2018)</STRONG></stronghuge> <br>
        <huge><em>Director of Information & News Committee</em></huge><br>
        <p></p>
        <p></p>
          <li> Managed and promoted SCUT SSE social media publicity (<em>e.g.</em>, SCUT iSoftware), which had connected and served over 500 SCUT SSE students. <br></li>
          <li> Organized technical training and provided professional IT supports for SCUT SSE activities.<br></li>
          <li> Co-organized more than three programming/software competitions.<br></li>
      </li></td>
    </tr>
   </tbody>
</table>


<tbody><tr>
        <td width="100%" valign="middle">
          <h2>Personal Interests</h2>
          <div style="line-height:25px">
          <p></p>
              <strong>Running and Working Out</strong>: I enjoy running and often participate in 10km+ level races including Singapore Marathon 2023.
              I regularly work out in the gym.
              <br>
               <strong>Military Chess (A Chinese cooperative and tactical game)</strong>：My most playing chess game during my high school.
              <br>
              <strong>Billiards, Archery, Rock Climbing, Texas Hold'em</strong>
              <p></p>
          </li></div>
        </td>
      </tr>
</tbody>


</table>
<!--<a href="https://clustrmaps.com/site/1bzxq" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=n&d=nb8WgzFOb-OXHK8yfVHTflus9_ERzuTcAVldtBvX_eg" /></a>-->
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=nb8WgzFOb-OXHK8yfVHTflus9_ERzuTcAVldtBvX_eg'></script>
</div>

<div id="footer">
  <div class="container">
      <div class="foot-madeby">The template is shared by <a href="https://zxjwudi.github.io/xuejiaozhao/"> Dr. Xuejiao Zhao.</a> Last update: 21 June 2024.</div>
  </div>
</div>

</div>
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="./js/scripts.js"></script>
<!-- <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>
</html>